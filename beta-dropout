import numpy as np
import random
def sigmoid(x):
  return 1 / (1 + np.exp(-x))

def deriv_sigmoid(x):
  fx = sigmoid(x)
  return fx * (1 - fx)

def mse_loss(y_true, y_pred):
  return ((y_true - y_pred) ** 2).mean()

class NeuralNetwork:
  def _init_(self):
    self.w=[]
    for i in range(0,40):
        self.w.append(np.random.normal())
    self.b=[]
    for i in range(0,11):
        self.b.append(np.random.normal())
  def feedforward(self, x,B):
    h=[]
    for i in range(0,10):
        rnd=random.uniform(0,1)
        if(rnd>B):
            h.append(0)
            continue
        temp=0
        for j in range(i*3,i*3+3):
            temp+=self.w[j]*x[j%3]
        h.append(sigmoid(temp+self.b[i]))
    temp=0
    for i in range(30,40):
        temp+=self.w[i]*h[i-30]
    o1 = sigmoid(temp+ self.b[10])
    return o1

  def train(self, data, all_y_trues):
    learn_rate = 0.1
    epochs = 2000
    for epoch in range(epochs):
      for x, y_true in zip(data, all_y_trues):
        # --- Do a feedforward (we'll need these values later)
        h=[]
        sum_h=[0]*10
        for i in range(0,10):
            temp=0
            for j in range(i*3,i*3+3):
                temp+=self.w[j]*x[j%3]
            sum_h[i]=temp+self.b[i]
            h.append(sigmoid(temp+self.b[i]))

        temp=0
        for i in range(30,40):
            temp+=self.w[i]*h[i-30]
        sum_o1=temp+self.b[10]
        o1 = sigmoid(temp+ self.b[10])

        y_pred = o1

        # --- Calculate partial derivatives.
        # --- Naming: d_L_d_w1 represents "partial L / partial w1"
        d_L_d_ypred = -2 * (y_true - y_pred)

        # Neuron o1
        d_ypred_d_w30 = h[0] * deriv_sigmoid(sum_o1)
        d_ypred_d_w31 = h[1] * deriv_sigmoid(sum_o1)
        d_ypred_d_w32 = h[2] * deriv_sigmoid(sum_o1)
        d_ypred_d_w33 = h[3] * deriv_sigmoid(sum_o1)
        d_ypred_d_w34 = h[4] * deriv_sigmoid(sum_o1)
        d_ypred_d_w35 = h[5] * deriv_sigmoid(sum_o1)
        d_ypred_d_w36 = h[6] * deriv_sigmoid(sum_o1)
        d_ypred_d_w37 = h[7] * deriv_sigmoid(sum_o1)
        d_ypred_d_w38 = h[8] * deriv_sigmoid(sum_o1)
        d_ypred_d_w39 = h[9] * deriv_sigmoid(sum_o1)
        d_ypred_d_b10 = deriv_sigmoid(sum_o1)

        d_ypred_d_h1 = self.w[30] * deriv_sigmoid(sum_o1)
        d_ypred_d_h2 = self.w[31] * deriv_sigmoid(sum_o1)
        d_ypred_d_h3 = self.w[32] * deriv_sigmoid(sum_o1)
        d_ypred_d_h4 = self.w[33] * deriv_sigmoid(sum_o1)
        d_ypred_d_h5 = self.w[34] * deriv_sigmoid(sum_o1)
        d_ypred_d_h6 = self.w[35] * deriv_sigmoid(sum_o1)
        d_ypred_d_h7 = self.w[36] * deriv_sigmoid(sum_o1)
        d_ypred_d_h8 = self.w[37] * deriv_sigmoid(sum_o1)
        d_ypred_d_h9 = self.w[38] * deriv_sigmoid(sum_o1)
        d_ypred_d_h10 = self.w[39] * deriv_sigmoid(sum_o1)
        
        # Neuron h1
        d_h1_d_w1 = x[0] * deriv_sigmoid(sum_h[0])
        d_h1_d_w2 = x[1] * deriv_sigmoid(sum_h[0])
        d_h1_d_w3 = x[2] * deriv_sigmoid(sum_h[0])
        d_h1_d_b1 = deriv_sigmoid(sum_h[0])

        # Neuron h2
        d_h2_d_w4 = x[0] * deriv_sigmoid(sum_h[1])
        d_h2_d_w5= x[1] * deriv_sigmoid(sum_h[1])
        d_h2_d_w6 = x[2] * deriv_sigmoid(sum_h[1])
        d_h2_d_b2 = deriv_sigmoid(sum_h[1])

        # Neuron h3
        d_h3_d_w7 = x[0] * deriv_sigmoid(sum_h[2])
        d_h3_d_w8 = x[1] * deriv_sigmoid(sum_h[2])
        d_h3_d_w9 = x[2] * deriv_sigmoid(sum_h[2])
        d_h3_d_b3 = deriv_sigmoid(sum_h[2])

        # Neuron h4
        d_h4_d_w10 = x[0] * deriv_sigmoid(sum_h[3])
        d_h4_d_w11 =x[1] * deriv_sigmoid(sum_h[3])
        d_h4_d_w12 = x[2] * deriv_sigmoid(sum_h[3])
        d_h4_d_b4 = deriv_sigmoid(sum_h[3])
        # Neuron h5
        d_h5_d_w13 = x[0] * deriv_sigmoid(sum_h[4])
        d_h5_d_w14 = x[1] * deriv_sigmoid(sum_h[4])
        d_h5_d_w15 = x[2] * deriv_sigmoid(sum_h[4])
        d_h5_d_b5 = deriv_sigmoid(sum_h[4])

        # Neuron h6
        d_h6_d_w16 = x[0] * deriv_sigmoid(sum_h[5])
        d_h6_d_w17= x[1] * deriv_sigmoid(sum_h[5])
        d_h6_d_w18 = x[2] * deriv_sigmoid(sum_h[5])
        d_h6_d_b6 = deriv_sigmoid(sum_h[5])
        # Neuron h7
        d_h7_d_w19 = x[0] * deriv_sigmoid(sum_h[6])
        d_h7_d_w20 = x[1] * deriv_sigmoid(sum_h[6])
        d_h7_d_w21 = x[2] * deriv_sigmoid(sum_h[6])
        d_h7_d_b7 = deriv_sigmoid(sum_h[6])

        # Neuron h8
        d_h8_d_w22 = x[0] * deriv_sigmoid(sum_h[7])
        d_h8_d_w23= x[1] * deriv_sigmoid(sum_h[7])
        d_h8_d_w24 = x[2] * deriv_sigmoid(sum_h[7])
        d_h8_d_b8 = deriv_sigmoid(sum_h[7])
        # Neuron h9
        d_h9_d_w25 = x[0] * deriv_sigmoid(sum_h[8])
        d_h9_d_w26 = x[1] * deriv_sigmoid(sum_h[8])
        d_h9_d_w27 = x[2] * deriv_sigmoid(sum_h[8])
        d_h9_d_b9 = deriv_sigmoid(sum_h[8])

        # Neuron h10
        d_h10_d_w28 = x[0] * deriv_sigmoid(sum_h[9])
        d_h10_d_w29= x[1] * deriv_sigmoid(sum_h[9])
        d_h10_d_w30 = x[2] * deriv_sigmoid(sum_h[9])
        d_h10_d_b10 = deriv_sigmoid(sum_h[9])

        # --- Update weights and biases
        # Neuron h1
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w2
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w3
        self.b[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_b1
        
        # Neuron h2
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w4
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w5
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_w6
        self.b[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2
        
        # Neuron h3
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_w7
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_w8
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_w9
        self.b[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h3 * d_h3_d_b3
        
        # Neuron h4
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_w10
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_w11
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_w12
        self.b[3] -= learn_rate * d_L_d_ypred * d_ypred_d_h4 * d_h4_d_b4
        
        # Neuron h5
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h5 * d_h5_d_w13
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h5 * d_h5_d_w14
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h5 * d_h5_d_w15
        self.b[4] -= learn_rate * d_L_d_ypred * d_ypred_d_h5 * d_h5_d_b5
        
        # Neuron h6
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h6 * d_h6_d_w16
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h6 * d_h6_d_w17
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h6 * d_h6_d_w18
        self.b[5] -= learn_rate * d_L_d_ypred * d_ypred_d_h6 * d_h6_d_b6
        
        # Neuron h7
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h7* d_h7_d_w19
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h7 * d_h7_d_w20
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h7 * d_h7_d_w21
        self.b[6] -= learn_rate * d_L_d_ypred * d_ypred_d_h7 * d_h7_d_b7
        
        # Neuron h8
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h8 * d_h8_d_w22
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h8 * d_h8_d_w23
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h8 * d_h8_d_w24
        self.b[7] -= learn_rate * d_L_d_ypred * d_ypred_d_h8 * d_h8_d_b8
        
        # Neuron h9
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h9 * d_h9_d_w25
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h9 * d_h9_d_w26
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h9 * d_h9_d_w27
        self.b[8] -= learn_rate * d_L_d_ypred * d_ypred_d_h9 * d_h9_d_b9
        
        # Neuron h10
        self.w[0] -= learn_rate * d_L_d_ypred * d_ypred_d_h10 * d_h10_d_w28
        self.w[1] -= learn_rate * d_L_d_ypred * d_ypred_d_h10* d_h10_d_w29
        self.w[2] -= learn_rate * d_L_d_ypred * d_ypred_d_h10 * d_h10_d_w30
        self.b[9] -= learn_rate * d_L_d_ypred * d_ypred_d_h10 * d_h10_d_b10
        
        # Neuron o1
        self.w[30] -= learn_rate * d_L_d_ypred * d_ypred_d_w30
        self.w[31] -= learn_rate * d_L_d_ypred * d_ypred_d_w31
        self.w[32] -= learn_rate * d_L_d_ypred * d_ypred_d_w32
        self.w[33] -= learn_rate * d_L_d_ypred * d_ypred_d_w33
        self.w[34] -= learn_rate * d_L_d_ypred * d_ypred_d_w34
        self.w[35] -= learn_rate * d_L_d_ypred * d_ypred_d_w35
        self.w[36] -= learn_rate * d_L_d_ypred * d_ypred_d_w36
        self.w[37] -= learn_rate * d_L_d_ypred * d_ypred_d_w37
        self.w[38] -= learn_rate * d_L_d_ypred * d_ypred_d_w38
        self.w[39] -= learn_rate * d_L_d_ypred * d_ypred_d_w39
        
        self.b[10] -= learn_rate * d_L_d_ypred * d_ypred_d_b10

      # --- Calculate total loss at the end of each epoch
      if epoch % 10 == 0:
        y_preds = np.apply_along_axis(self.feedforward, 1, data,2)
        loss = mse_loss(all_y_trues, y_preds)
        print("Epoch %d loss: %f" % (epoch, loss))

# Define dataset
data = np.array([
  [-2, -1,3],
  [25, 6,4],   
  [17, 4,9],   
  [-15, -6,-2],
])
#define output
all_y_trues = np.array([
  1,
  0,
  0,
  1, 
])

# Train our neural network!
network = NeuralNetwork()
network.train(data, all_y_trues)

# Make some predictions
emily = np.array([-7, -3,-1]) #1st test case
frank = np.array([20, 2,-6])  #2nd test case
print("1st test case: %f" % network.feedforward(emily,0.6)) 
print("2nd test case: %f" % network.feedforward(frank,0.3))
